---
title: "Mixed-Effects Models"
subtitle: "Misc. Hierarchical Examples-Crossed" 
output:
  html_document:
    toc: yes
---

```{r setup2, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
packages_needed <- c("ggplot2", # graphics
                     "dplyr",
                     "arm", # display() etc.
                     "MASS",
                     "ggfortify",
                     "nlme",
                     "lme4",
                     "lmerTest",
                     "emmeans",
                     "ggtext",
                     "patchwork"
                     )
pk_to_install <- packages_needed [!( packages_needed %in% rownames(installed.packages())  )]
if(length(pk_to_install)>0 ){
  install.packages(pk_to_install,repos="http://cran.r-project.org")
}
#lapply(packages_needed, require, character.only = TRUE)
library(ggplot2)
library(dplyr)
library(arm)
library(MASS)
library(ggfortify)
library(nlme)
library(lme4)
library(lmerTest)
library(emmeans)
library(ggtext)
library(patchwork)

sys.source("../scripts/theme_cmg.R", envir = knitr::knit_global())
```

Background: <https://www.youtube.com/watch?v=-4K-kKXNths>

Up to this point our analyses have dealt mainly with just one or two explanatory variables, and for the most part these have been experimental treatments that have been deliberately applied in a particular way.
These types of explanatory variables are often referred to as **fixed effects** (we fix the levels of the experimental treatments).

However, there is often hierarchical structure in our data, such as with blocked designs.
Sometimes we deliberately choose to have blocked designs, but in other cases they are forced upon us by circumstances.
Sometimes we might know how the blocks differ, but this knowledge is never complete and we often have little idea how or why one block differs from another.
We just know that blocks will differ due to the ubiquitous variability of the natural world.

These blocking terms and related variables go by a variety of names including nuisance variables and **random effects**.
Statistical models that include both fixed and random effects are called mixed-effects models, or sometimes just **mixed models**.

**Fixed vs. Random Effects** Dingemanse and Dochtermann (2013; J. Animal Ecology 82:39-54)

Mixed-effect models incorporate two types of parameters:

1.  The effects that predictor variables -- which can be continuous (covariates) or categorical (factors) -- have on the mean of response variables. Such effects are called **'fixed'** whenever specific effects are estimated at their observed levels (e.g. differences in means between four specific years of study).

A "fixed variable" is one that is assumed to be measured without error (e.g. sex).

It is also assumed that the values of a fixed variable in one study are the same as the values of the fixed variable in another study (e.g. burned, unburned; control, experimental).

2.  Effects on response variables generated by variation within and among levels of a predictor variable (factor). Effects of such predictor variables are called **'random'** whenever variance is estimated among **observed levels sampled from a population of levels**.

You can think of the values of random variables as representing a random sample of all possible values or instances of that variable (age, IQ, body mass, blood pressure), including repeated sampling of replicates (individuals, plots, etc) across time.

We expect to generalize the results obtained with a random variable to all other possible instances of that value.
In traditional ANOVA and regression analysis we assume the predictor variables are fixed, but mixed-effects models allow us to relax that assumption (and calculations are also relaxed).

**Part One**\
**Repeated Measures Example**\
One of the main assumptions of a traditional OLS regression model is that collected samples are independent.
What about a design where you measure the same replicates more than once, like a before-after comparison?
Observations are obviously not independent.

![](../images/gingko.jpg){width="50%"}

```{r make fake Gingko data}
treat  = rep(c('treat', 'control'), e=5)
pre = c(31,12,53,24,15,36,17,38,20,10)
post = c(41,50,80,60,50,20,19,38,50,12)

dfwide <- data.frame(id=factor(1:10), treat, pre, post) #wide data frame
dflong <- tidyr::gather(dfwide, key=time, value=score, pre:post) %>% arrange(id) #long dataframe
dflong$time = factor(dflong$time, levels = c("pre", "post")) #reorder factor to be pre then post
```

```{r plot the Gingko data, message=FALSE, warning=FALSE}
ggplot(dflong, aes(x=time, y=score, color=treat)) + 
  geom_line(aes(group=id)) +
  geom_point(size=3) +
  ggtitle(label = "Effect of Gingko on Test of Memory Performance",
          subtitle = "n = 10 participants") +
  theme_cmg()

```

```{r fit linear model}
#fit an OLS linear model in the way we are accustomed to.
olsModel <- lm(score ~ treat + time + treat*time, data=dflong)
anova(olsModel)
```

**THIS IS WHAT NOT TO DO! This model has ONLY Fixed Effects.**\
This model is fit using only fixed effects, producing WAY too many residual df.
Does not account for the hierarchical nature of the experiment; individuals are tested multiple times in each treatment.
Number of individuals was only n=10, so this model has artificially inflated sample size.
This analysis can't possibly be correct.

Need to fit a model that accounts for the repeated measurement of individuals (each person twice).

We will use a new package called `lme4` and the function `lmer` (linear mixed effects regression).

```{r fit mixed model}
#note new syntax for model specification
lmeModel <- lmer(score ~ treat*time + (1|id), data=dflong)
anova(lmeModel)
#notice that the default for mixed models has slightly different output than normal OLS model.
```

However, now we are using a tool that can handle additional time points, continuous covariates with possibly nonlinear relationships, different types of outcome variables, other correlational structures among the observations, etc.
In fact, if one looks at the help file for `aov`, one will note that it suggests using `lme` for unbalanced designs and other situations.\

\
\
[*The slot machine example "Machine" is an example of a mixed-model with unbalanced sample sizes.*]{style="color:blue"}

**Machine** Unbalanced repeated measures ANOVA; Data are ratings for three slot machine types, each used by six different players.\

\
We can model this as a mixed-model ANOVA since we have repeated measurements from each individual; often playing more than once on each machine type (treatment).
Data can be considered hierarchical.\
(Example from JMP: Machine.jmp; model specification slightly different than example).

![](../images/slots.png)

```{r import machine data, message=FALSE}
data <- read.csv("../data/Machine2.csv")
data$person <- as.factor(data$person) #make person ID a factor
```

```{r plot individual across machines, fig.height = 8, message=FALSE, warning=FALSE}
p1a<- ggplot(data, aes(x=machine, y=rating, group=person, color=person, shape=person)) + 
  geom_point(size=4, position = position_dodge2(width=.33, preserve = "total")) +
  scale_y_continuous(labels=scales::dollar_format()) +
  #geom_line() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title="The Bandit Gives Back: Rating Slot Machines",
       subtitle = "Notice unbalanced sampling of individuals",
       x= "Slot Machine", 
       y = "Yield/$100 played")

#box plot of raw data; does not adjust for repeated measures of individuals
p1b <- ggplot(data, aes(x=machine, y=rating, color=machine)) + 
  geom_boxplot() +
  scale_y_continuous(labels=scales::dollar_format()) +
  labs(title="The Bandit Gives Back: Rating Slot Machines",
       subtitle = "Raw data; does not adjust for repeated measures of individuals",
       x= "Slot Machine", 
       y = "Yield/$100 played")

  p1a / p1b #uses library(patchwork) for plot organization)
```

```{r summarize machine data and plot, message=FALSE}
machines_means <- data %>%
  group_by(machine) %>%
  summarise(mean_rating=mean(rating),
            se_rating=sd(rating)/sqrt(n()))
machines_means
```

```{r fit mixed model for machines, message=FALSE, warning=FALSE}
mixed_machine <- lmer(rating~(machine*person)+(1|person), data = data)

anova(mixed_machine) #notice it doesn't report whether whole model is significant or model fit, but we likely don't care anyway.
```

```{r summarize machine model}
summary(mixed_machine)
#most likely you have no interest in this table, but one helpful thing is that it reports
#"Number of obs: 44, groups:  person, 6", so you know its accounted for the repeated measures
```

```{r check machine model, fig.width=9.5, fig.height=9}
performance::check_model(mixed_machine)
```

```{r fit emmeans from model - each machine}
#calculate model-adjusted means (e.g. estimated marginal means)
mixed_machine_emm <- emmeans(mixed_machine, "machine")
mixed_machine_emm
```

```{r fit emmeans from model - each person}
emmeans(mixed_machine, "person")
```

```{r fit emmeans from model - each person*machine}
emmeans(mixed_machine, "machine", "person") #reverse the order of factors for alternative output
```

```{r fit emmeans from model - each person*machine [alternate format]}
emmeans(mixed_machine, "person", "machine")
```

OK, so lets look at the raw means vs. model-adjusted means (esimated marginal means)

```{r emmeans as dataframe for use in plotting}
data_emm <- as.data.frame(mixed_machine_emm)
data_emm
#model-adjusted means (emm) are different than raw means (see above); adjusted for the same person repeatedly evaluating the machines.
```

```{r}
machines_means
```

```{r use pictures as labels, message=TRUE}
#https://github.com/wilkelab/ggtext
labels <- c(
  bell = "<img src='../images/bell.jpg' width='75' /><br>Bell of Fortune", #redefine labels based on groups in df
  diamond = "<img src='../images/diamond.jpg' width='75' /><br>Diamond Blitz",
  fruit = "<img src='../images/fruit.jpg' width='75' /><br>Fruit Bonanza"
)
```

```{r plot machine emmeans, message=TRUE}
##put raw means next to emmeans for visualization
p2<- ggplot(data_emm, aes(x=machine, y=emmean)) + 
  geom_point(size=4) +
  geom_errorbar(aes(ymin=emmean-SE, ymax=emmean+SE), width=.2) +
  labs(title="The Bandit Gives Back: Rating Popular Slot Machines", x= NULL, y = "Machine Rating (yield/$100 played)") +
  geom_point(data=machines_means, size=4, x=machines_means$machine, y=machines_means$mean_rating, color="blue") +
  theme(axis.text.x = ggtext::element_markdown(color = "blue", size = 12)) +
  scale_x_discrete(name = NULL, labels = labels) +
  ylim(50, 67)

p2
```

Raw means are not all that different from model-adjusted means (emmeans), but does change the inference slightly.

```{r pairwise contrasts BETWEEN machines}
pairs(emmeans(mixed_machine, "machine")) 
```

```{r pairwise contrasts BETWEEN people}
pairs(emmeans(mixed_machine, "person"))
```

```{r all season:machine pairwise CONTRASTS}
emmeans(mixed_machine, specs = pairwise ~ machine:person)
#probably no a priori reason to use this table, but here it is.
```

\
\
![](../images/coyote-fox.jpg){width="50%"}\
[*The coyote-fox home range example "Animals" is an example of a mixed-model with perfectly balanced sample sizes. It describes the movement distances of the two species across each of the four seasons.*]{style="color:green"}

**Animals**

```{r import animal data, message=FALSE}
Animals <- read.csv("../data/Animals.csv")
```

```{r summarize animal data and plot, message=FALSE}
summary <- Animals %>%
  group_by(species, season) %>%
  summarise(n = n(),
           mean_move=mean(miles),
           se_move=sd(miles)/sqrt(n()))
            
summary
```

```{r}
mixed_animals <- lmer(miles~species*season+(1|subject), data = Animals)
#note syntax for model specification:compact syntax
anova(mixed_animals) #gives us tests for fixed effects
```

```{r}
summary(mixed_animals)
```

```{r check animal model, fig.width=9.5, fig.height=9, message=FALSE}
performance::check_model(mixed_animals) #analogous to autoplot, but for more complex models
```

```{r emmeans}
#calculate model-adjusted means (e.g. estimated marginal means)
mixed_animals_emm <- emmeans(mixed_animals, "season", "species")
mixed_animals_emm
```

```{r emmeans as dataframe}
data_emm <- as.data.frame(summary(mixed_animals_emm))
#data_emm <- as.data.frame(summary(mixed_animals_emm))[c('season', 'species', 'emmean', 'SE')] #specify columns to print
data_emm
#model-adjusted means (emm) are identical to raw means (see above) since nothing really being adjusted in fully balanced experiment.
```

```{r}
#notice that SE is same value for all emmeans: this is expected

#https://www.ibm.com/support/pages/estimated-marginal-means-all-have-same-standard-error-spss#:~:text=Both%20are%20correct%2C%20because%20the,variation%20about%20that%20group's%20mean.&text=The%20model%20is%20that%20each,same%20for%20all%20the%20groups.

#https://stats.stackexchange.com/questions/444707/standard-error-in-estimated-marginal-means-are-all-the-same

#https://github.com/jamovi/jamovi/issues/660
```

```{r plot animal emmeans}
#relevel factors into intuitive order
data_emm$season <- factor(data_emm$season, levels = c("fall", "winter", "spring", "summer"))

p<- ggplot(data_emm, aes(x=season, y=emmean, group=species, color=species)) + 
  geom_line() +
  geom_point(size=4)+
  geom_errorbar(aes(ymin=emmean-SE, ymax=emmean+SE), width=.2)+
  labs(title="Distance Traveled Per Season (marginal means +/- 1 SE)", x="Season", y = "Distance Traveled (miles)")
p
```

```{r seasonal contrasts BETWEEN species}
pairs(emmeans(mixed_animals, "species", "season"))
```

```{r seasonal contrasts WITHIN species, Tukey adjusted}
pairs(emmeans(mixed_animals, "season", "species"))
#pairs(mixed_animals_emm)
```

```{r all season:species pairwise CONTRASTS}
emmeans(mixed_animals_emm, specs = pairwise ~ season:species)
#probably no a priori reason to use this table, but here it is.
```
